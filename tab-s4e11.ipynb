{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"},{"sourceId":9926714,"sourceType":"datasetVersion","datasetId":5990290}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install category_encoders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:24.51049Z","iopub.execute_input":"2024-11-16T22:33:24.511296Z","iopub.status.idle":"2024-11-16T22:33:24.516001Z","shell.execute_reply.started":"2024-11-16T22:33:24.511251Z","shell.execute_reply":"2024-11-16T22:33:24.514987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.api.types import is_object_dtype, is_numeric_dtype, is_bool_dtype\n\nimport sklearn\nsklearn.set_config(transform_output=\"pandas\")\nimport category_encoders as ce\n\nfrom sklearn.preprocessing import OrdinalEncoder, RobustScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, GradientBoostingClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom lightgbm.sklearn import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier, Pool\nimport xgboost as xgb\n\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T00:52:05.926069Z","iopub.execute_input":"2024-12-20T00:52:05.926363Z","iopub.status.idle":"2024-12-20T00:52:11.093365Z","shell.execute_reply.started":"2024-12-20T00:52:05.926331Z","shell.execute_reply":"2024-12-20T00:52:11.092174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/playground-series-s4e11/test.csv\")\nsub = pd.read_csv(\"/kaggle/input/playground-series-s4e11/sample_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:24.533789Z","iopub.execute_input":"2024-11-16T22:33:24.534138Z","iopub.status.idle":"2024-11-16T22:33:25.209986Z","shell.execute_reply.started":"2024-11-16T22:33:24.534101Z","shell.execute_reply":"2024-11-16T22:33:25.208985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This variable allows to run or not various pre-processing techniques\nDO = \"norm_7\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.211238Z","iopub.execute_input":"2024-11-16T22:33:25.211588Z","iopub.status.idle":"2024-11-16T22:33:25.219786Z","shell.execute_reply.started":"2024-11-16T22:33:25.211551Z","shell.execute_reply":"2024-11-16T22:33:25.218755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LABEL = \"Depression\"\nCAT_COLUMNS = df_train.select_dtypes(include=['object']).columns.tolist()\nNUM_COLUMNS = [c for c in df_train.columns if c not in CAT_COLUMNS + [\"id\", LABEL]]\nFEATURES = CAT_COLUMNS +  NUM_COLUMNS\n\nSPLITS = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.222033Z","iopub.execute_input":"2024-11-16T22:33:25.222407Z","iopub.status.idle":"2024-11-16T22:33:25.243875Z","shell.execute_reply.started":"2024-11-16T22:33:25.22237Z","shell.execute_reply":"2024-11-16T22:33:25.24294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 30 SPLITS","metadata":{}},{"cell_type":"code","source":"\"\"\"\nSPLIT :  1\nScore CB: 0.9149253731343283\nScore LGB 0.929637526652452\nScore XGB 0.9373134328358209\nScore HGB 0.9383795309168443\nScore GB 0.9402985074626866\nScore RF 0.9353944562899786\nScore LR 0.9353944562899786\nScore final 30 splits  :  0.9330490405117271\nScore from vals 30 splits  :  0.9353944562899786\n\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.245116Z","iopub.execute_input":"2024-11-16T22:33:25.245419Z","iopub.status.idle":"2024-11-16T22:33:25.252005Z","shell.execute_reply.started":"2024-11-16T22:33:25.245386Z","shell.execute_reply":"2024-11-16T22:33:25.251034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10 SPLITS - Results I gor for various versions","metadata":{}},{"cell_type":"code","source":"\"\"\"\nVersion 38\nSPLIT :  1\nScore XGB 0.9414356787491116\nScore HGB 0.9398009950248756\nScore LR 0.9393745557924662\nScore final 10 splits  :  0.9402037431888178\n\nVersion 39\nSPLIT :  1\nScore CB: 0.9243781094527364\nScore LGB 0.9350390902629708\nScore XGB 0.9414356787491116\nScore HGB 0.9394456289978678\nScore LR 0.9393745557924662\nScore final 10 splits  :  0.9359346126510306\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.253313Z","iopub.execute_input":"2024-11-16T22:33:25.253683Z","iopub.status.idle":"2024-11-16T22:33:25.264878Z","shell.execute_reply.started":"2024-11-16T22:33:25.253641Z","shell.execute_reply":"2024-11-16T22:33:25.263568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 20 SPLITS","metadata":{}},{"cell_type":"code","source":"\"\"\"\nVersion 55\nSPLIT :  1\nScore XGB 0.9448471926083867\nScore HGB 0.9444207533759773\nScore GB 0.9439943141435678\nScore final 20 splits  :  0.9444207533759773\nScore from vals 20 splits  :  0.9449893390191898\n\nVersion 56\nSPLIT :  1\nScore XGB 0.9448471926083867\nScore HGB 0.9444207533759773\nScore GB 0.9439943141435678\nScore LR 0.9424307036247335\nScore final 20 splits  :  0.9439232409381664\nScore from vals 20 splits  :  0.9448471926083867\n\nVersion 54\nSPLIT :  1\nScore XGB 0.9448471926083867\nScore HGB 0.9422885572139303\nScore GB 0.9421464108031272\nScore final 20 splits  :  0.9430940535418147\n\nVersion 37\nScore XGB 0.9448471926083867\nScore HGB 0.9417199715707179\nScore LR 0.940724946695096\nScore final 20 splits  :  0.9424307036247335\n\nVersion 52\nSPLIT :  1\nScore XGB 0.9448471926083867\nScore HGB 0.9431414356787491\nScore GB 0.9402985074626866\nScore RF 0.942999289267946\nScore LR 0.940724946695096\nScore final 20 splits  :  0.9424022743425728\n\n\n\nVersion 49\nSPLIT :  1\nScore CB: 0.9279317697228145\nScore LGB 0.9395877754086709\nScore XGB 0.9448471926083867\nScore HGB 0.9425728500355366\nScore GB 0.9417199715707179\nScore RF 0.941862117981521\nScore LR 0.940724946695096\nScore final 20 splits  :  0.939892374860392\n\nVersion 47\nSPLIT :  1\nScore CB: 0.9279317697228145\nScore LGB 0.9395877754086709\nScore XGB 0.9448471926083867\nScore HGB 0.9437100213219616\nScore LR 0.940724946695096\nScore final 20 splits  :  0.939360341151386\n\nVersion 40\nSPLIT :  1\nScore CB: 0.9279317697228145\nScore LGB 0.9395877754086709\nScore XGB 0.9448471926083867\nScore HGB 0.9425728500355366\nScore LR 0.940724946695096\nScore final 20 splits  :  0.939132906894101\n\n\n\n\nSPLIT :  1\nScore CB: 0.9279317697228145\nScore LGB 0.9395877754086709\nScore XGB 0.9448471926083867\nScore HGB 0.941862117981521\nScore LR 0.9198294243070363 ( + class weight)\nScore final 20 splits  :  0.9348116560056858\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.266196Z","iopub.execute_input":"2024-11-16T22:33:25.266497Z","iopub.status.idle":"2024-11-16T22:33:25.275851Z","shell.execute_reply.started":"2024-11-16T22:33:25.266464Z","shell.execute_reply":"2024-11-16T22:33:25.274857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colx = df_train[\"Name\"].unique()\ncolv = df_test[\"Name\"].unique()\n\ncolx_vc = df_train[\"Name\"].value_counts()\ncolv_vc = df_test[\"Name\"].value_counts()\n\ncol_name_v = [c for c in colv if c not in colx]\ncol_name_x = [c for c in colx if c not in colv]\n\ndef parse_degree(df, train_df=True):\n    COLUMN = \"Degree\"\n    cols = ['Mechanical Engineer', 'Travel Consultant', 'Magan', 'Doctor', 'Nalini', 'Degree', 'Badhya', 'HR Manager', 'Bhavesh', 'Business Analyst', '0', 'Mthanya', 'Working Professional', 'UX/UI Designer', 'Esha', 'Plumber', '24', '29', '8.95', 'Aadhya', '20', 'Vivaan', 'Advait', 'B.Study_Hours', 'Vibha','B. Gender','Gagan','5.65','Eshita','Navya','Pune', 'Bian','Kavya','Vrinda', 'M', 'E.Ed', '3.0','Moham','Rupak','Banchal', 'X/UI Designer', 'Veda', 'Bhopal', 'Kalyan', 'Unite', '5.61', 'Brit', 'B.03', 'Ritik', '5.56', '7.06', 'Brithika', 'Pihu', 'Jhanvi', 'Aarav', 'Entrepreneur', '8.56', 'Mahika', 'Lata', 'S.Arch', 'Marsh','5.88', 'B.3.79', 'Mihir', 'Data Scientist']\n    \n    col_vc = df[COLUMN].value_counts()\n    one_vals = [i for i in col_vc.index if col_vc[i] < 100]\n\n    if DO in [\"norm_6\", \"norm_7\"]:\n        df.loc[df[COLUMN].isin(cols), COLUMN] = \"FAKE\"\n        df.loc[df[COLUMN].isin(one_vals), COLUMN] = \"RARE\"\n    elif DO in [\"norm_4\", \"norm_5\"]:\n        df.loc[df[COLUMN].isin(cols+one_vals), COLUMN] = np.nan\n    else:\n        if train_df:\n            df = df.loc[~df[COLUMN].isin(cols+one_vals)]\n        else:\n            df.loc[df[COLUMN].isin(cols+one_vals), COLUMN] = np.nan\n            \n    return df    \n        \n\ndef parse_dietary_habits(df, train_df=True):\n    COLUMN = \"Dietary Habits\"\n    cols = ['Yes', 'No', 'MCA', 'Resistant', 'Pratham', 'Gender', '3', '1.0', 'Mihir', 'Vegas', 'Electrician', 'M.Tech', 'Class 12', 'Male', '2', 'Indoor', 'Prachi', 'Hormonal', 'Academic', 'Educational', 'Soham', 'Vivaan', 'Raghav', 'Naina', 'Kolkata', 'BSc']\n    \n    col_vc = df[COLUMN].value_counts()\n    one_vals = [i for i in col_vc.index if col_vc[i] < 100]\n    \n    if DO in [\"norm_6\", \"norm_7\"]:\n        df.loc[df[COLUMN].isin(cols), COLUMN] = -10\n        df.loc[df[COLUMN].isin(one_vals), COLUMN] = -20\n    elif DO in [\"norm_4\", \"norm_5\"]:\n        df.loc[df[COLUMN].isin(cols+one_vals), COLUMN] = np.nan\n    else:\n        if train_df:\n            df = df.loc[~df[COLUMN].isin(cols)]    \n        else:\n            df.loc[df[\"Dietary Habits\"].isin(cols+one_vals), COLUMN] = np.nan\n            \n    df.loc[df[COLUMN]=='5 Healthy', COLUMN] = \"Healthy\"\n    df.loc[df[COLUMN]=='5 Unhealthy', COLUMN] = \"Unhealthy\"\n      \n    df.loc[df[COLUMN]=='Moderate', COLUMN] = 3\n    df.loc[df[COLUMN]=='Healthy', COLUMN] = 4\n    df.loc[df[COLUMN]=='Unhealthy', COLUMN] = 1\n    df.loc[df[COLUMN]=='Less than Healthy', COLUMN] = 2\n    df.loc[df[COLUMN]=='Less Healthy', COLUMN] = 2\n    df.loc[df[COLUMN]=='No Healthy', COLUMN] = 1\n    df.loc[df[COLUMN]=='More Healthy', COLUMN] = 5\n    df.loc[df[COLUMN]=='Mealy', COLUMN] = 3\n    \n    df[COLUMN] = df[COLUMN].astype(np.float32)\n    \n    return df\n\n\ndef parse_profession(df, train_df=True):\n    COLUMN = \"Profession\"\n    cols_profession_to_delete = ['PhD','MBBS', 'B.Ed','M.Ed','BBA','MBA', 'LLM','BCA','B.Com', 'BE','Simran', '3M', 'Name', 'No', '24th', 'Unveil', 'Unhealthy', 'Yuvraj', 'Yogesh', 'Patna', 'Nagpur', 'Pranav', 'Visakhapatnam', 'Moderate', 'Manvi', 'Yogesh', 'Samar', 'Surat']\n         \n    col_vc = df[COLUMN].value_counts()\n    one_vals = [i for i in col_vc.index if col_vc[i] < 100]\n\n    if DO in [\"norm_6\", \"norm_7\"]:\n        df.loc[df[COLUMN].isin(cols_profession_to_delete), COLUMN] = \"FAKE\"\n        df.loc[df[COLUMN].isin(one_vals), COLUMN] = \"RARE\"\n    elif DO in [\"norm_4\", \"norm_5\"]:\n        df.loc[df[COLUMN].isin(cols_profession_to_delete+one_vals), COLUMN] = np.nan\n    else:    \n        if train_df:\n            df = df.loc[~df[COLUMN].isin(cols_profession_to_delete+one_vals)]\n        else:\n            df.loc[df[COLUMN].isin(cols_profession_to_delete+one_vals), COLUMN] = np.nan\n        \n    return df\n\n\ndef parse_city(df, train_df=True):\n    COLUMN = \"City\"\n    cols_city_to_delete =  ['3.0', 'City', 'Less than 5 Kalyan', 'No', 'No.12', 'M.Tech', 'MCA', 'ME', 'M.Com']\n    \n    col_vc = df[COLUMN].value_counts()\n    one_vals = [i for i in col_vc.index if col_vc[i] < 100]\n\n    if DO in [\"norm_6\", \"norm_7\"]:\n        df.loc[df[COLUMN].isin(cols_city_to_delete), COLUMN] = \"FAKE\"\n        df.loc[df[COLUMN].isin(one_vals), COLUMN] = \"RARE\"\n    elif DO in [\"norm_4\", \"norm_5\"]:\n        df.loc[df[COLUMN].isin(cols_city_to_delete+one_vals), COLUMN] = np.nan\n    else:    \n        if train_df:\n            df = df.loc[~df[COLUMN].isin(cols_city_to_delete+one_vals)]\n        else:\n            df.loc[df[COLUMN].isin(cols_city_to_delete+one_vals), COLUMN] = np.nan\n        \n    return df\n    \ndef parse_sleeping_duration(df, train_df=True):\n    COLUMN = \"Sleep Duration\"\n    cols_sleping_duration_to_delete = [\"No\", \"Vivian\", \"Vivan\", \"Meerut\", \"Have_you_ever_had_suicidal_thoughts\", \"Sleep_Duration\", \"Work_Study_Hours\", \"Pune\", \"Indore\"]\n    \n    col_vc = df[COLUMN].value_counts()\n    one_vals = [i for i in col_vc.index if col_vc[i] < 100]\n\n    if DO in [\"norm_6\", \"norm_7\"]:\n        df.loc[df[COLUMN].isin(cols_sleping_duration_to_delete), COLUMN] = -10\n        df.loc[df[COLUMN].isin(one_vals), COLUMN] = -20\n    elif DO in [\"norm_4\", \"norm_5\"]:\n        df.loc[df[COLUMN].isin(cols_sleping_duration_to_delete+one_vals), COLUMN] = np.nan\n    else:    \n        if train_df:\n            df = df.loc[~df[COLUMN].isin(cols_sleping_duration_to_delete+one_vals)]\n        else:\n            df.loc[df[COLUMN].isin(cols_sleping_duration_to_delete+one_vals), COLUMN] = np.nan\n            \n    df.loc[df[COLUMN]=='60-65 hours', COLUMN] = 63\n    df.loc[df[COLUMN]=='8-89 hours', COLUMN] = 85\n    df.loc[df[COLUMN]=='20-21 hours', COLUMN] = 20.5\n    df.loc[df[COLUMN]=='6 hours', COLUMN] = 6\n    df.loc[df[COLUMN]=='50-75 hours', COLUMN] = 50\n    df.loc[df[COLUMN]=='9-10 hours', COLUMN] = 9.5\n    df.loc[df[COLUMN]=='5-6 hours', COLUMN] = 5.5\n    df.loc[df[COLUMN]=='7-8 hours', COLUMN] = 7.5\n    df.loc[df[COLUMN]=='1-2 hours', COLUMN] = 1.5\n    df.loc[df[COLUMN]=='4-6 hours', COLUMN] = 4.5\n    df.loc[df[COLUMN]=='6-7 hours', COLUMN] = 6.5\n    df.loc[df[COLUMN]=='10-11 hours', COLUMN] = 10\n    df.loc[df[COLUMN]=='8-9 hours', COLUMN] = 8.5\n    df.loc[df[COLUMN]=='6-8 hours', COLUMN] = 7\n    df.loc[df[COLUMN]=='3-4 hours', COLUMN] = 3.5\n    df.loc[df[COLUMN]=='2-3 hours', COLUMN] = 2.5\n    df.loc[df[COLUMN]=='40-45 hours', COLUMN] = 42.5\n    df.loc[df[COLUMN]=='1-3 hours', COLUMN] = 2\n    df.loc[df[COLUMN]=='9-11 hours', COLUMN] = 10\n    df.loc[df[COLUMN]=='4-5 hours', COLUMN] = 4.5\n    df.loc[df[COLUMN]=='55-66 hours', COLUMN] = 60.5\n    df.loc[df[COLUMN]=='9-6 hours', COLUMN] = 7.5\n    df.loc[df[COLUMN]=='1-6 hours', COLUMN] = 3.5\n    df.loc[df[COLUMN]=='35-36 hours', COLUMN] = 35.5\n    df.loc[df[COLUMN]=='45-48 hours', COLUMN] = 46.5\n    df.loc[df[COLUMN]=='10-6 hours', COLUMN] = 8.1\n    df.loc[df[COLUMN]=='8 hours', COLUMN] = 8\n    df.loc[df[COLUMN]=='49 hours', COLUMN] = 49\n    df.loc[df[COLUMN]=='3-6 hours', COLUMN] = 4.5\n    df.loc[df[COLUMN]=='9-5 hours', COLUMN] = 7\n    df.loc[df[COLUMN]=='9-5', COLUMN] = 7\n    df.loc[df[COLUMN]=='Unhealthy', COLUMN] = 1\n    df.loc[df[COLUMN]=='No', COLUMN] = 0\n    df.loc[df[COLUMN]=='than 5 hours', COLUMN] = 5\n    df.loc[df[COLUMN]=='Less than 5 hours', COLUMN] = 4.9\n    df.loc[df[COLUMN]=='More than 8 hours', COLUMN] = 8\n    df.loc[df[COLUMN]=='Moderate', COLUMN] = 6\n    df.loc[df[COLUMN]=='45', COLUMN] = 45\n    df.loc[df[COLUMN]=='0', COLUMN] = 0\n    df[COLUMN] = df[COLUMN].astype(np.float32)\n    return df\n    \ndef parse_cat(df, train_df=True):\n    #if \"Name\" in df.columns:\n    #    df.drop(columns=[\"Name\"], inplace=True)\n    df = parse_sleeping_duration(df, train_df)\n    df = parse_city(df, train_df)\n    df = parse_profession(df, train_df)\n    df = parse_dietary_habits(df, train_df)\n    df = parse_degree(df, train_df)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.279262Z","iopub.execute_input":"2024-11-16T22:33:25.279724Z","iopub.status.idle":"2024-11-16T22:33:25.421615Z","shell.execute_reply.started":"2024-11-16T22:33:25.279688Z","shell.execute_reply":"2024-11-16T22:33:25.420603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nif DO != \"\": \n    df_train = parse_cat(df_train)\n    df_test = parse_cat(df_test, train_df=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:25.423401Z","iopub.execute_input":"2024-11-16T22:33:25.42387Z","iopub.status.idle":"2024-11-16T22:33:27.9274Z","shell.execute_reply.started":"2024-11-16T22:33:25.423817Z","shell.execute_reply":"2024-11-16T22:33:27.926448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[\"missing\"] = df_train.isna().sum(axis=1)\ndf_test[\"missing\"] = df_test.isna().sum(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:28.004895Z","iopub.execute_input":"2024-11-16T22:33:28.005283Z","iopub.status.idle":"2024-11-16T22:33:28.266622Z","shell.execute_reply.started":"2024-11-16T22:33:28.005243Z","shell.execute_reply":"2024-11-16T22:33:28.265503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CAT_COLUMNS = df_train.select_dtypes(include=['object']).columns.tolist()\nNUM_COLUMNS = [c for c in df_train.columns if c not in CAT_COLUMNS + [\"id\", LABEL]]\nFEATURES = CAT_COLUMNS +  NUM_COLUMNS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:28.267941Z","iopub.execute_input":"2024-11-16T22:33:28.268298Z","iopub.status.idle":"2024-11-16T22:33:28.300172Z","shell.execute_reply.started":"2024-11-16T22:33:28.268262Z","shell.execute_reply":"2024-11-16T22:33:28.299051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if DO == \"\":\n    COLS_TO_ENCODE = CAT_COLUMNS\nelse:    \n    COLS_TO_ENCODE = [\"Name\", \"Gender\", \"City\", \"Working Professional or Student\", \"Profession\", \"Degree\", \"Have you ever had suicidal thoughts ?\", \"Family History of Mental Illness\"]\n\n# Concat train and test in order not to have unknown values. \n# This might work for these mid-level competitions.\ndf_all = pd.concat([df_train[FEATURES], df_test[FEATURES]])\n\n#oe = OrdinalEncoder(encoded_missing_value = -1, handle_unknown='use_encoded_value', unknown_value=-1)\noe = ce.TargetEncoder(COLS_TO_ENCODE)\noe.fit(df_train[COLS_TO_ENCODE], df_train[LABEL])\ndf_train[COLS_TO_ENCODE] = oe.transform(df_train[COLS_TO_ENCODE])\ndf_test[COLS_TO_ENCODE] = oe.transform(df_test[COLS_TO_ENCODE])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:28.301519Z","iopub.execute_input":"2024-11-16T22:33:28.301846Z","iopub.status.idle":"2024-11-16T22:33:30.065919Z","shell.execute_reply.started":"2024-11-16T22:33:28.301811Z","shell.execute_reply":"2024-11-16T22:33:30.064806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[COLS_TO_ENCODE] = df_train[COLS_TO_ENCODE].fillna(\"NAN\")\ndf_test[COLS_TO_ENCODE] = df_test[COLS_TO_ENCODE].fillna(\"NAN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.067183Z","iopub.execute_input":"2024-11-16T22:33:30.067543Z","iopub.status.idle":"2024-11-16T22:33:30.090587Z","shell.execute_reply.started":"2024-11-16T22:33:30.067507Z","shell.execute_reply":"2024-11-16T22:33:30.089422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A test I did but gave a poorer score\nif DO == \"norm_5\":\n    imp = IterativeImputer(estimator=HistGradientBoostingRegressor(), missing_values=-1)\n\n    df_all = pd.concat([df_train[FEATURES], df_test[FEATURES]])\n    imp.fit(df_all[COLS_TO_ENCODE])\n    df_train[COLS_TO_ENCODE] = imp.transform(df_train[COLS_TO_ENCODE])\n    df_train[COLS_TO_ENCODE] = df_train[COLS_TO_ENCODE].round()\n    df_test[COLS_TO_ENCODE] = imp.transform(df_test[COLS_TO_ENCODE])\n    df_test[COLS_TO_ENCODE] = df_test[COLS_TO_ENCODE].round()\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.091894Z","iopub.execute_input":"2024-11-16T22:33:30.092259Z","iopub.status.idle":"2024-11-16T22:33:30.103126Z","shell.execute_reply.started":"2024-11-16T22:33:30.09222Z","shell.execute_reply":"2024-11-16T22:33:30.102013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"se = SimpleImputer()\nse.fit(df_train[NUM_COLUMNS])\ndf_train[NUM_COLUMNS] = se.transform(df_train[NUM_COLUMNS])\ndf_test[NUM_COLUMNS] = se.transform(df_test[NUM_COLUMNS])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.104507Z","iopub.execute_input":"2024-11-16T22:33:30.1049Z","iopub.status.idle":"2024-11-16T22:33:30.185877Z","shell.execute_reply.started":"2024-11-16T22:33:30.104859Z","shell.execute_reply":"2024-11-16T22:33:30.184765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"se = RobustScaler()\nse.fit(df_train[NUM_COLUMNS])\n\ndf_train_rs = df_train.copy()\ndf_test_rs = df_test.copy()\n\ndf_train_rs[NUM_COLUMNS] = se.transform(df_train[NUM_COLUMNS])\ndf_test_rs[NUM_COLUMNS] = se.transform(df_test[NUM_COLUMNS])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.187165Z","iopub.execute_input":"2024-11-16T22:33:30.187526Z","iopub.status.idle":"2024-11-16T22:33:30.311158Z","shell.execute_reply.started":"2024-11-16T22:33:30.187489Z","shell.execute_reply":"2024-11-16T22:33:30.309877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_train.fillna(-1, inplace=True)\n#df_test.fillna(-1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.312571Z","iopub.execute_input":"2024-11-16T22:33:30.312916Z","iopub.status.idle":"2024-11-16T22:33:30.317325Z","shell.execute_reply.started":"2024-11-16T22:33:30.312878Z","shell.execute_reply":"2024-11-16T22:33:30.316194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_test.to_csv(\"test_\"+DO+\".csv\", index=False)\n#df_train.to_csv(\"train_\"+DO+\".csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.318734Z","iopub.execute_input":"2024-11-16T22:33:30.319128Z","iopub.status.idle":"2024-11-16T22:33:30.327772Z","shell.execute_reply.started":"2024-11-16T22:33:30.319088Z","shell.execute_reply":"2024-11-16T22:33:30.326844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#corr = df_train.corr()\n#sns.heatmap(corr);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.328919Z","iopub.execute_input":"2024-11-16T22:33:30.329278Z","iopub.status.idle":"2024-11-16T22:33:30.336884Z","shell.execute_reply.started":"2024-11-16T22:33:30.329242Z","shell.execute_reply":"2024-11-16T22:33:30.335939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df_train[FEATURES]\nY = df_train[LABEL]\n\nX_rs = df_train_rs[FEATURES]\nY_rs = df_train_rs[LABEL]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.338245Z","iopub.execute_input":"2024-11-16T22:33:30.338785Z","iopub.status.idle":"2024-11-16T22:33:30.365467Z","shell.execute_reply.started":"2024-11-16T22:33:30.338734Z","shell.execute_reply":"2024-11-16T22:33:30.364608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Best parameters obtained with Optuna for various algorithms :","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LightGBM\n# 0.9395877754086709 - Splits 20\n# 0.929637526652452 - Splits 30\nparams_lgb =  {'reg_lambda': 0.0026698283995182604, 'reg_alpha': 0.0989129184454625, 'colsample_bytree': 1.0, 'learning_rate': 0.060731608923579795, 'n_estimators': 3085, 'max_depth': 21, 'num_leaves': 41, 'min_split_gain ': 0.7936829445500752, 'boosting_type': 'gbdt', 'min_child_weight': 1, 'min_child_samples': 15, 'subsample': 0.4, 'class_weight': 'balanced', 'verbose': -1, 'objective': 'binary', 'random_state': 0}\n\n\n# CatBoost\n# 0.9279317697228145 - Splits 20\n# 0.9149253731343283 - Splits 30\nparams_cb = {'reg_lambda': 0.8352770337753764, 'learning_rate': 0.02208182328039188, 'iterations': 3853, 'max_depth': 16, 'bagging_temperature': 21, 'grow_policy': 'Lossguide', 'max_leaves': 181, 'min_data_in_leaf': 37, 'early_stopping_rounds': 96, 'random_state': 0, 'auto_class_weights': 'Balanced', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'logging_level': 'Silent'}\n\n\n#XGBoost\n# 0.9448471926083867 - Splits 20\n# 0.9373134328358209 - Splits 30\nparams_xgb = {'reg_lambda': 1.5428511958840945, 'reg_alpha': 1.9784889391087677, 'colsample_bytree': 0.24941596115970358, 'colsample_bylevel': 0.7741734319140999, 'colsample_bynode': 0.48878500754238585, 'subsample': 0.8, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'booster': 'gbtree', 'learning_rate': 0.7120749229294119, 'n_estimators': 4308, 'max_depth': 6, 'max_leaves': 35, 'random_state': 0, 'min_child_weight': 0.6958532789138221, 'num_parallel_tree': 7, 'importance_type': 'cover', 'early_stopping_rounds': 92, 'verbosity': None}\n\n\n# LogisticRegression\n# 0.9408670931058991 - Splits 20\n# 0.9353944562899786 - Splits 30\nparams_lr = {'penalty': 'l2', 'C': 3.0004668024183463, 'max_iter': 4175, 'solver': 'newton-cg', 'random_state': 0, 'fit_intercept': True, 'verbose': 0}\n\n\n#HistGradientBoosting\n# 0.9444207533759773 - Splits 20\nparams_hgb = {'max_iter': 1520, 'l2_regularization': 8.191871920529406, 'learning_rate': 0.06118116610086637, 'max_depth': 36, 'random_state': 0, 'max_leaf_nodes': 78, 'early_stopping': 'auto', 'verbose': 0}\n#{'max_iter': 2304, 'max_leaf_nodes': 17, 'l2_regularization': 7.995559326469298, 'learning_rate': 0.6463109974953717, 'max_depth': 25, 'random_state': 0, 'early_stopping': 'auto', 'verbose': 0}\n\n\n# 0.9383795309168443 - Splits 30\nparams_hgb_30 = {'max_iter': 1344, 'l2_regularization': 0.8759140605723984, 'learning_rate': 0.0739467989453549, 'max_depth': 22, 'random_state': 0, 'max_leaf_nodes': 88, 'early_stopping': 'auto', 'verbose': 0}\n\n\n#GradientBoosting\n# 0.9439943141435678 - Splits 20\nparams_gb = {'n_estimators': 3333, 'subsample': 0.9698554748709222, 'min_samples_split': 0.6662565698253853, 'min_samples_leaf': 0.0007345948700016973, 'min_weight_fraction_leaf': 0.014786932404866664, 'learning_rate': 0.978339301630668, 'max_depth': 87, 'random_state': 0, 'max_leaf_nodes': 24, 'n_iter_no_change': 5, 'verbose': 0}\n\n# 0.9402985074626866 - Splits 30\nparams_gb_30 = {'n_estimators': 4451, 'subsample': 0.8965541536141035, 'min_samples_split': 0.1903502832441657, 'min_samples_leaf': 0.00438540641029464, 'min_weight_fraction_leaf': 0.027896901188861886, 'learning_rate': 0.31155313567602394, 'max_depth': 57, 'random_state': 0, 'max_leaf_nodes': 66, 'n_iter_no_change': 27, 'verbose': 0}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.36665Z","iopub.execute_input":"2024-11-16T22:33:30.367116Z","iopub.status.idle":"2024-11-16T22:33:30.38281Z","shell.execute_reply.started":"2024-11-16T22:33:30.367076Z","shell.execute_reply":"2024-11-16T22:33:30.381789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_cb = 0\npred_xgb = 0\npred_lgb = 0\npred_hgb = 0\npred_gb = 0\npred_rf = 0\npred_lr = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.384193Z","iopub.execute_input":"2024-11-16T22:33:30.385367Z","iopub.status.idle":"2024-11-16T22:33:30.395655Z","shell.execute_reply.started":"2024-11-16T22:33:30.385315Z","shell.execute_reply":"2024-11-16T22:33:30.39471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run or not certain algorithms in order to merge predictions: ","metadata":{}},{"cell_type":"code","source":"DO_CB = True\nDO_LGB = True\nDO_XGB = False\nDO_HGB = True\nDO_GB = False\nDO_RF = False\nDO_LR = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.396929Z","iopub.execute_input":"2024-11-16T22:33:30.397353Z","iopub.status.idle":"2024-11-16T22:33:30.405892Z","shell.execute_reply.started":"2024-11-16T22:33:30.397315Z","shell.execute_reply":"2024-11-16T22:33:30.405035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if DO in [\"norm_7\"]:\n    df_folds = pd.read_csv(\"/kaggle/input/db-s4e11/tabular_s4e11_folds_\"+str(SPLITS)+\".csv\")\n\n    pred_val_cb = 0\n    pred_val_xgb = 0\n    pred_val_lgb = 0\n    pred_val_hgb = 0\n    pred_val_gb = 0\n    pred_val_rf = 0\n    pred_val_lr = 0\n    \n    count_algos = 0\n    score_final = 0\n\n    pred_val = 0\n    \n    for VAL in range(1, 2):\n        print(\"SPLIT : \", VAL)\n        id_val = df_folds.loc[df_folds[\"folds\"]==VAL, \"id\"]\n        id_train = df_folds.loc[df_folds[\"folds\"]!=VAL, \"id\"]\n        \n        X_train = df_train.loc[df_train[\"id\"].isin(id_train), FEATURES]\n        X_val = df_train.loc[df_train[\"id\"].isin(id_val), FEATURES]\n        y_train = df_train.loc[df_train[\"id\"].isin(id_train), LABEL]\n        y_val = df_train.loc[df_train[\"id\"].isin(id_val), LABEL]\n\n        if DO_CB:\n            model_cb = CatBoostClassifier(**params_cb)\n            model_cb.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n            pred_cb += model_cb.predict_proba(df_test[FEATURES])\n            pred_val_cb += model_cb.predict_proba(X_val)\n\n            pred_val += pred_val_cb\n    \n            score_cb = accuracy_score(y_val, np.argmax(pred_val_cb, axis=1))\n            print(\"Score CB:\", score_cb)\n\n            count_algos = count_algos + 1\n            score_final += score_cb\n\n        if DO_LGB:\n            model = LGBMClassifier(**params_lgb)\n            model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n            pred_lgb += model.predict_proba(df_test[FEATURES])\n            pred_val_lgb += model.predict_proba(X_val)\n\n            pred_val += pred_val_lgb\n            \n            score_lgb = accuracy_score(y_val, np.argmax(pred_val_lgb, axis=1))\n            print(\"Score LGB\", score_lgb)\n\n            count_algos = count_algos + 1\n            score_final += score_lgb\n\n        if DO_XGB:\n            model_xgb = xgb.XGBClassifier(**params_xgb)\n            model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n            pred_xgb += model_xgb.predict_proba(df_test[FEATURES])\n            pred_val_xgb += model_xgb.predict_proba(X_val)\n\n            pred_val += pred_val_xgb\n    \n            score_xgb = accuracy_score(y_val, np.argmax(pred_val_xgb, axis=1))\n            print(\"Score XGB\", score_xgb)\n\n            count_algos = count_algos + 1\n            score_final += score_xgb\n\n        if DO_HGB:\n            if SPLITS == 30:\n                params_hgb = params_hgb_30\n                \n            model_hgb = HistGradientBoostingClassifier(**params_hgb)\n            model_hgb.fit(X_train, y_train)\n            pred_hgb += model_hgb.predict_proba(df_test[FEATURES])\n            pred_val_hgb += model_hgb.predict_proba(X_val)\n\n            pred_val += pred_val_hgb\n    \n            score_hgb = accuracy_score(y_val, np.argmax(pred_val_hgb, axis=1))\n            print(\"Score HGB\", score_hgb)   \n\n            count_algos = count_algos + 1\n            score_final +=  score_hgb\n\n        if DO_GB:\n            if SPLITS == 30:\n                params_gb = params_gb_30\n                \n            model_gb = GradientBoostingClassifier(**params_gb)\n            model_gb.fit(X_train, y_train)\n            pred_gb += model_gb.predict_proba(df_test[FEATURES])\n            pred_val_gb += model_gb.predict_proba(X_val)\n\n            pred_val += pred_val_gb\n    \n            score_gb = accuracy_score(y_val, np.argmax(pred_val_gb, axis=1))\n            print(\"Score GB\", score_gb)   \n\n            count_algos = count_algos + 1\n            score_final += score_gb\n\n        if DO_RF:\n            model_rf = RandomForestClassifier()\n            model_rf.fit(X_train, y_train)\n            pred_rf += model_rf.predict_proba(df_test[FEATURES])\n            pred_val_rf += model_rf.predict_proba(X_val)\n\n            pred_val += pred_val_rf\n    \n            score_rf = accuracy_score(y_val, np.argmax(pred_val_rf, axis=1))\n            print(\"Score RF\", score_rf)   \n\n            count_algos = count_algos + 1\n            score_final += score_rf\n        \n        if DO_LR:\n            model_lr = LogisticRegression(**params_lr)\n            model_lr.fit(X_train, y_train)\n            pred_lr += model_lr.predict_proba(df_test[FEATURES])\n            pred_val_lr += model_lr.predict_proba(X_val)\n\n            pred_val += pred_val_lr\n    \n            score_lr = accuracy_score(y_val, np.argmax(pred_val_lr, axis=1))\n            print(\"Score LR\", score_lr)    \n\n            count_algos = count_algos + 1\n            score_final += score_lr\n\n    \n    score_final /= float(count_algos)\n    \n    print(\"Score final\", SPLITS, \"splits\", \" : \", score_final)\n    \n    score_from_vals = accuracy_score(y_val, np.argmax(pred_val, axis=1))\n    print(\"Score from vals\", SPLITS, \"splits\", \" : \", score_from_vals)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:30.407557Z","iopub.execute_input":"2024-11-16T22:33:30.407899Z","iopub.status.idle":"2024-11-16T22:33:34.671983Z","shell.execute_reply.started":"2024-11-16T22:33:30.407863Z","shell.execute_reply":"2024-11-16T22:33:34.670848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nif DO not in [\"norm_7\"]:\n    if DO in [\"norm_5\"]:\n        model = CatBoostClassifier(**params_cb)\n        model.fit(X_rs,Y_rs)\n        pred_cb = model.predict_proba(df_test_rs[FEATURES])\n    elif DO not in [\"norm_7\"]:\n        model = CatBoostClassifier(logging_level=\"Silent\")\n        model.fit(X_rs,Y_rs)\n        pred_cb = model.predict_proba(df_test_rs[FEATURES])\n    \n    if DO in [\"norm_5\"]:\n        model = LGBMClassifier(**params_lgb)\n    else:\n        model = LGBMClassifier(verbose=-1)\n    model.fit(X,Y)\n    pred_lgb = model.predict_proba(df_test[FEATURES])\n    \n    model_xgb = xgb.XGBClassifier(verbose=-1)\n    model_xgb.fit(X,Y)\n    pred_xgb = model_xgb.predict_proba(df_test[FEATURES])\n\n\npred = pred_cb + pred_lgb + pred_xgb + pred_hgb + pred_gb + pred_lr + pred_val_rf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:34.673484Z","iopub.execute_input":"2024-11-16T22:33:34.674208Z","iopub.status.idle":"2024-11-16T22:33:34.687763Z","shell.execute_reply.started":"2024-11-16T22:33:34.674155Z","shell.execute_reply":"2024-11-16T22:33:34.686472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub[LABEL] = np.argmax(pred, axis=1)\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T22:33:34.70823Z","iopub.execute_input":"2024-11-16T22:33:34.709174Z","iopub.status.idle":"2024-11-16T22:33:34.87787Z","shell.execute_reply.started":"2024-11-16T22:33:34.709125Z","shell.execute_reply":"2024-11-16T22:33:34.87669Z"}},"outputs":[],"execution_count":null}]}